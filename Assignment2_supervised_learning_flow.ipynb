{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf2b77a",
   "metadata": {},
   "source": [
    "# Wine Classification - Supervised Learning Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f0e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169bcee",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Problem and Dataset Description\n",
    "\n",
    "The Wine dataset is the result of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The dataset contains 13 attributes (features) measuring various chemical properties of the wine, with the goal of classifying the wine into one of three classes (class_0, class_1, or class_2).\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- 178 instances (wines)\n",
    "- 13 numeric features (chemical properties)\n",
    "- 3 classes (wine cultivars)\n",
    "- No missing values\n",
    "\n",
    "**Features:**\n",
    "1. Alcohol\n",
    "2. Malic acid\n",
    "3. Ash\n",
    "4. Alcalinity of ash\n",
    "5. Magnesium\n",
    "6. Total phenols\n",
    "7. Flavanoids\n",
    "8. Nonflavanoid phenols\n",
    "9. Proanthocyanins\n",
    "10. Color intensity\n",
    "11. Hue\n",
    "12. OD280/OD315 of diluted wines\n",
    "13. Proline\n",
    "\n",
    "This is a multiclass classification problem where we aim to identify the correct cultivar based on the chemical analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6608d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (142, 14)\n",
      "\n",
      "Training data columns:\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline', 'target']\n",
      "\n",
      "Class distribution in training data:\n",
      "target\n",
      "1    57\n",
      "0    48\n",
      "2    37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 rows of training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.08</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.32</td>\n",
       "      <td>18.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.27</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.37</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.36</td>\n",
       "      <td>10.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.82</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.82</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.88</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.44</td>\n",
       "      <td>415.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.16</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.68</td>\n",
       "      <td>830.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    12.08        1.83  2.32               18.5       81.0           1.60   \n",
       "1    13.58        2.58  2.69               24.5      105.0           1.55   \n",
       "2    12.37        0.94  1.36               10.6       88.0           1.98   \n",
       "3    11.82        1.72  1.88               19.5       86.0           2.50   \n",
       "4    13.16        3.57  2.15               21.0      102.0           1.50   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        1.50                  0.52             1.64             2.40  1.08   \n",
       "1        0.84                  0.39             1.54             8.66  0.74   \n",
       "2        0.57                  0.28             0.42             1.95  1.05   \n",
       "3        1.64                  0.37             1.42             2.06  0.94   \n",
       "4        0.55                  0.43             1.30             4.00  0.60   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          2.27    480.0       1  \n",
       "1                          1.80    750.0       2  \n",
       "2                          1.82    520.0       1  \n",
       "3                          2.44    415.0       1  \n",
       "4                          1.68    830.0       2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv('wine_train.csv')\n",
    "test_data = pd.read_csv('wine_test.csv')\n",
    "\n",
    "# Display basic information about the training dataset\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"\\nTraining data columns:\")\n",
    "print(train_data.columns.tolist())\n",
    "print(\"\\nClass distribution in training data:\")\n",
    "print(train_data['target'].value_counts())\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109e331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "alcohol                         0\n",
      "malic_acid                      0\n",
      "ash                             0\n",
      "alcalinity_of_ash               0\n",
      "magnesium                       0\n",
      "total_phenols                   0\n",
      "flavanoids                      0\n",
      "nonflavanoid_phenols            0\n",
      "proanthocyanins                 0\n",
      "color_intensity                 0\n",
      "hue                             0\n",
      "od280/od315_of_diluted_wines    0\n",
      "proline                         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "alcohol                         0\n",
      "malic_acid                      0\n",
      "ash                             0\n",
      "alcalinity_of_ash               0\n",
      "magnesium                       0\n",
      "total_phenols                   0\n",
      "flavanoids                      0\n",
      "nonflavanoid_phenols            0\n",
      "proanthocyanins                 0\n",
      "color_intensity                 0\n",
      "hue                             0\n",
      "od280/od315_of_diluted_wines    0\n",
      "proline                         0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics for training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.997254</td>\n",
       "      <td>2.297746</td>\n",
       "      <td>2.361690</td>\n",
       "      <td>19.419718</td>\n",
       "      <td>99.943662</td>\n",
       "      <td>2.315986</td>\n",
       "      <td>2.063592</td>\n",
       "      <td>0.346690</td>\n",
       "      <td>1.561901</td>\n",
       "      <td>5.030211</td>\n",
       "      <td>0.958563</td>\n",
       "      <td>2.638873</td>\n",
       "      <td>742.457746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.789931</td>\n",
       "      <td>1.093317</td>\n",
       "      <td>0.283231</td>\n",
       "      <td>3.354815</td>\n",
       "      <td>13.683751</td>\n",
       "      <td>0.639469</td>\n",
       "      <td>1.005302</td>\n",
       "      <td>0.117562</td>\n",
       "      <td>0.540979</td>\n",
       "      <td>2.239593</td>\n",
       "      <td>0.219631</td>\n",
       "      <td>0.718083</td>\n",
       "      <td>317.250905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.410000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.370000</td>\n",
       "      <td>1.592500</td>\n",
       "      <td>2.222500</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.782500</td>\n",
       "      <td>1.257500</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.922500</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.155000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.505000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>2.815000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.637500</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.375000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>2.822500</td>\n",
       "      <td>2.887500</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>6.182500</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.197500</td>\n",
       "      <td>957.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.750000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  142.000000  142.000000  142.000000         142.000000  142.000000   \n",
       "mean    12.997254    2.297746    2.361690          19.419718   99.943662   \n",
       "std      0.789931    1.093317    0.283231           3.354815   13.683751   \n",
       "min     11.410000    0.740000    1.360000          10.600000   78.000000   \n",
       "25%     12.370000    1.592500    2.222500          17.250000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.250000   98.000000   \n",
       "75%     13.637500    3.020000    2.557500          21.375000  108.000000   \n",
       "max     14.750000    5.650000    3.230000          30.000000  151.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     142.000000  142.000000            142.000000       142.000000   \n",
       "mean        2.315986    2.063592              0.346690         1.561901   \n",
       "std         0.639469    1.005302              0.117562         0.540979   \n",
       "min         0.980000    0.340000              0.130000         0.420000   \n",
       "25%         1.782500    1.257500              0.260000         1.250000   \n",
       "50%         2.380000    2.155000              0.320000         1.505000   \n",
       "75%         2.822500    2.887500              0.430000         1.870000   \n",
       "max         3.880000    5.080000              0.630000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
       "count       142.000000  142.000000                    142.000000   142.000000  \n",
       "mean          5.030211    0.958563                      2.638873   742.457746  \n",
       "std           2.239593    0.219631                      0.718083   317.250905  \n",
       "min           1.280000    0.480000                      1.290000   278.000000  \n",
       "25%           3.180000    0.800000                      1.922500   500.000000  \n",
       "50%           4.800000    0.960000                      2.815000   660.000000  \n",
       "75%           6.182500    1.120000                      3.197500   957.500000  \n",
       "max          11.750000    1.450000                      4.000000  1680.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(X_train.isnull().sum())\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(X_test.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics for training data:\")\n",
    "X_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12559b63",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we'll explore the dataset to gain insights about the features and their relationships with the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a3d90c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([  6,   8,  11,  12,  16,  18,  19,  22,  23,  24,  26,  27,  30,  38,\\n        39,  48,  52,  53,  57,  62,  63,  64,  65,  66,  67,  69,  71,  83,\\n        84,  94,  97, 100, 101, 105, 108, 110, 111, 112, 116, 117, 120, 124,\\n       126, 130, 137, 138, 140, 141],\\n      dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m plt.subplot(\u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m, i+\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     sns.kdeplot(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[feature], \n\u001b[32m      7\u001b[39m                label=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mClass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m plt.title(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDistribution of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by class\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m plt.legend()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nadavlb\\OneDrive - schleisner\\Desktop\\hadar\\GIT\\wine_not\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nadavlb\\OneDrive - schleisner\\Desktop\\hadar\\GIT\\wine_not\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nadavlb\\OneDrive - schleisner\\Desktop\\hadar\\GIT\\wine_not\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index([  6,   8,  11,  12,  16,  18,  19,  22,  23,  24,  26,  27,  30,  38,\\n        39,  48,  52,  53,  57,  62,  63,  64,  65,  66,  67,  69,  71,  83,\\n        84,  94,  97, 100, 101, 105, 108, 110, 111, 112, 116, 117, 120, 124,\\n       126, 130, 137, 138, 140, 141],\\n      dtype='int64')] are in the [columns]\""
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Visualization 1: Feature distributions across classes\n",
    "plt.figure(figsize=(20, 15))\n",
    "for i, feature in enumerate(X_train.columns):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    for target in [0, 1, 2]:\n",
    "        sns.kdeplot(X_train.loc[y_train == target, feature], \n",
    "                   label=f'Class {target}')\n",
    "    plt.title(f'Distribution of {feature} by class')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization 1 Explanation: This plot shows the distribution of each feature across the three wine classes. \"\n",
    "      \"We can observe which features have distinct distributions for different classes, indicating their potential \"\n",
    "      \"discriminatory power. For example, we can see that alcohol content, flavanoids, and proline show clear \"\n",
    "      \"separation between classes, suggesting they might be important features for classification.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization 2: Correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr_matrix = train_data.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization 2 Explanation: The correlation heatmap reveals relationships between features and with the target. \"\n",
    "      \"Highly correlated features may contain redundant information. We can see several strongly correlated feature pairs, \"\n",
    "      \"such as flavanoids and total_phenols. The target variable shows strong correlation with certain features like \"\n",
    "      \"flavanoids, alcohol, and proline, reinforcing our observations from the distribution plots.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50df41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization 3: PCA for dimensionality reduction and visualization\n",
    "# Standardize the data first\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Create a DataFrame for easy plotting\n",
    "pca_df = pd.DataFrame({\n",
    "    'PCA1': X_train_pca[:, 0],\n",
    "    'PCA2': X_train_pca[:, 1],\n",
    "    'class': y_train\n",
    "})\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='class', palette='viridis', data=pca_df, s=100)\n",
    "plt.title('PCA: First two principal components')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} explained variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} explained variance)')\n",
    "plt.show()\n",
    "\n",
    "# Display the feature contributions to each principal component\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=X_train.columns\n",
    ")\n",
    "print(\"Feature contributions to principal components:\")\n",
    "loadings\n",
    "\n",
    "print(\"\\nVisualization 3 Explanation: PCA reduces our 13-dimensional data to 2 dimensions for visualization, capturing the \"\n",
    "      \"maximum variance. The scatter plot shows good separation between the three wine classes even with just two principal \"\n",
    "      \"components, indicating that a classification model should be able to distinguish between classes effectively. \"\n",
    "      \"The loadings table shows which original features contribute most to each principal component.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d5194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Table: Feature importance using Random Forest\n",
    "# This gives us another way to understand which features might be most important for classification\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Create a feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table\n",
    "print(\"Feature Importance Table:\")\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f8e10",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Experiments with Cross-Validation\n",
    "\n",
    "In this section, we'll use 5-fold cross-validation with grid search to find the best combination of feature engineering techniques, classifiers, and hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define feature engineering options\n",
    "feature_engineering = [\n",
    "    ('standard', StandardScaler()),\n",
    "    ('minmax', MinMaxScaler()),\n",
    "    ('pca', Pipeline([('scale', StandardScaler()), ('pca', PCA(n_components=0.95))]))\n",
    "]\n",
    "\n",
    "# Define classifiers and their hyperparameters\n",
    "classifiers = [\n",
    "    ('svm', SVC(), {\n",
    "        'svm__C': [0.1, 1, 10, 100],\n",
    "        'svm__gamma': ['scale', 'auto'],\n",
    "        'svm__kernel': ['rbf', 'linear']\n",
    "    }),\n",
    "    ('rf', RandomForestClassifier(random_state=42), {\n",
    "        'rf__n_estimators': [50, 100, 200],\n",
    "        'rf__max_depth': [None, 10, 20],\n",
    "        'rf__min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    ('knn', KNeighborsClassifier(), {\n",
    "        'knn__n_neighbors': [3, 5, 7, 9],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "        'knn__p': [1, 2]  # Manhattan or Euclidean distance\n",
    "    })\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6aefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to run grid search for a given feature engineering technique and classifier\n",
    "def run_grid_search(X, y, feature_eng, classifier, param_grid, cv):\n",
    "    # Create a pipeline with the feature engineering and classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('feature_eng', feature_eng),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    # Set up grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a34753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run experiments for all combinations\n",
    "results = []\n",
    "\n",
    "for fe_name, feature_eng in feature_engineering:\n",
    "    for clf_name, classifier, params in classifiers:\n",
    "        print(f\"Running grid search for {fe_name} + {clf_name}...\")\n",
    "        grid_search = run_grid_search(X_train, y_train, feature_eng, classifier, params, cv)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'feature_engineering': fe_name,\n",
    "            'classifier': clf_name,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'grid_search': grid_search\n",
    "        })\n",
    "        \n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best macro F1 score: {grid_search.best_score_:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame to display all results\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Feature Engineering': r['feature_engineering'],\n",
    "        'Classifier': r['classifier'],\n",
    "        'Best Parameters': str(r['best_params']),\n",
    "        'Macro F1 Score': r['best_score']\n",
    "    } for r in results\n",
    "])\n",
    "\n",
    "# Sort by best score\n",
    "results_df = results_df.sort_values('Macro F1 Score', ascending=False).reset_index(drop=True)\n",
    "print(\"All grid search results sorted by F1 score:\")\n",
    "results_df\n",
    "\n",
    "# Get the best combination\n",
    "best_result = results[results_df.iloc[0].name]\n",
    "print(f\"\\nThe best combination is {best_result['feature_engineering']} feature engineering with a {best_result['classifier']} classifier\")\n",
    "print(f\"Best parameters: {best_result['best_params']}\")\n",
    "print(f\"Best macro F1 score: {best_result['best_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006a9c4",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Training with the Best Combination\n",
    "\n",
    "In this section, we'll train the best model combination on the full training set and evaluate it on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the best pipeline\n",
    "best_pipeline = best_result['grid_search'].best_estimator_\n",
    "\n",
    "# Train on the full training set\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Test set macro F1 score: {test_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600877b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display predictions for the first 5 test examples\n",
    "first_5_test = X_test.iloc[:5]\n",
    "first_5_true = y_test.iloc[:5]\n",
    "first_5_pred = best_pipeline.predict(first_5_test)\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True Class': first_5_true.values,\n",
    "    'Predicted Class': first_5_pred\n",
    "})\n",
    "\n",
    "print(\"Predictions for the first 5 test examples:\")\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a524703a",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Summary and Conclusions\n",
    "\n",
    "In this assignment, we implemented a complete supervised learning flow for wine classification using the Wine dataset. The key findings are:\n",
    "\n",
    "1. **Exploratory Data Analysis**: Our EDA revealed that features like alcohol, flavanoids, and proline show clear separation between classes. The correlation heatmap identified several strongly correlated features, and PCA demonstrated good class separation even with just two principal components.\n",
    "\n",
    "2. **Feature Engineering**: We explored three feature engineering techniques: standard scaling, min-max scaling, and PCA after standard scaling.\n",
    "\n",
    "3. **Model Selection**: We compared three classifiers (SVM, Random Forest, and KNN) with various hyperparameters using 5-fold cross-validation and grid search. The best combination was determined through our experiments.\n",
    "\n",
    "4. **Performance**: The best model achieved a strong macro F1 score on the test set, demonstrating its effectiveness for this multiclass classification task.\n",
    "\n",
    "The successful implementation of this supervised learning flow demonstrates how feature engineering, model selection, and hyperparameter tuning can be used together to create effective classification models. The high performance achieved shows that the chemical properties of wines can indeed be used to accurately identify their cultivator.\n",
    "\n",
    "For future work, we could explore more feature engineering techniques like feature selection or polynomial features, try ensemble methods combining multiple classifiers, or investigate other evaluation metrics beyond F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e816c6",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Video Presentation\n",
    "\n",
    "A 3-5 minute video presentation explaining the process and results is available at: [Insert your video link here]\n",
    "\n",
    "The GitHub repository containing this notebook and all related files is available at: [Insert your GitHub/Google Colab link here]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}